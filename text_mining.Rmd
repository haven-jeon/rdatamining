---

Text Mining For Korean
========================================================

이번 섹션에서는 트위터 데이터를 활용한 텍스트 마이닝을 소개한다. 
주로 소개된 내용은 아래와 같다. 

* 데이터 획득 
* 전처리 
* 핵심어 추출, 단어간의 관계 파악 
* 워드 클라우드 
* 트위터 클러스터링 

--- 

## 데이터 획득 ##

[twitteR](http://cran.r-project.org/web/packages/twitteR/index.html) 패키지를 활용해 트위터 데이터를 가져온다. 

*교육 목적상 본문 분석에서는 필자가 직접 제공하는 데이터를 사용하고, 트위터 데이터 패치 해오는 코드만을 살펴본다.*



```{r init, message=FALSE}
library(twitteR)
# 
# n <- 200
# 
# keyword <- "삼성전자"
# 
# keyword <- enc2utf8(keyword)
# 
# rdmTweets <- searchTwitter(keyword,  n)

load(url("http://dl.dropbox.com/u/8686172/twitter.RData"))

nDocs <- length(rdmTweets)

```

사실 텍스트 전처리는 데이터 상황에 따라 가변적이다. 따라서 로(raw) 데이터를 먼저 확인해보고 본인이 어떤 목적으로 분석을 하는지 그 방향과 데이터가 맞는지 확인하고 방향과 일시키기 위해서 어떻게 전처리를 해야 되는 고민이 필요하다.  
일단 필자는 아래와 같은 전처리 계획을 세웠다. 


1. @ 트윗 태그 제거 
1. URL 제거 
1. 명사 추출 
1. 문장 부호 제거
1. 숫자 제거
1. 영어 소문자화 
1. 불용어 제거 


이를 위해 [KoNLP][konlp], [tm][tm] 패키지가 필요하다.

---

```{r preprocess, message=FALSE, warning=FALSE}
library(KoNLP)
library(tm)


df <- do.call("rbind", lapply(rdmTweets, as.data.frame))

removeTwit <- function(x) {gsub("@[[:graph:]]*", "", x)}

df$ptext <- sapply(df$text, removeTwit)

removeURL <- function(x) { gsub("http://[[:graph:]]*", "", x)}

df$ptext <- sapply(df$ptext, removeURL)
useSejongDic()
df$ptext <- sapply(df$ptext, function(x) {paste(extractNoun(x), collapse=" ")}) 

#build corpus
myCorpus_ <- Corpus(VectorSource(df$ptext))
myCorpus_ <- tm_map(myCorpus_, removePunctuation)
myCorpus_ <- tm_map(myCorpus_, removeNumbers)
myCorpus_ <- tm_map(myCorpus_, tolower)
myStopwords <- c(stopwords('english'), "rt")
myCorpus_ <-tm_map(myCorpus_, removeWords, myStopwords)

```

---


[tm][tm]패키지는 R에서 텍스트 마이닝을 위해 가장 빈번히 사용되는 패키지이다. 특히나 이 패키지는 Corpus라는 자료구조를 기반으로 분석을 수행하기 때문에 Corpus로 데이터를 변형하기 위한 과정이 필요하다. 
이 Corpus내에서 단어에 대한 집계와 빈도수 그리고 단어간의 관계에 대한 코드를 소개한다. 
 
* 단어-트윗 간의 매트릭스 
* 10이상의 빈도수를 가진 단어들 
* "lg" 단어에 대한 관련 단어

---

```{r eda, message=FALSE}

myTdm <- TermDocumentMatrix(myCorpus, control=list(wordLengths=c(2,Inf)))

#inspect frequent term
findFreqTerms(myTdm, lowfreq=10)

#inspect associations 
findAssocs(myTdm,'lg',0.25)
```


---

이들에 대한 플로팅을 해본다. 


[ggplot2](http://had.co.nz/ggplot2/)를 이용한 막대그림 

```{r fig.width=8, fig.height=10, message=FALSE, warning=FALSE}
library(ggplot2)

termFrequency <- rowSums(as.matrix(myTdm))
termFrequency <- subset(termFrequency,termFrequency>=10)

ggplot(data.frame(term = names(termFrequency), freq=termFrequency), aes(term, freq)) + geom_bar() + coord_flip()
```


---

단어 빈도수에 기반한 워드 크라우드 


```{r fig.width=8, fig.height=8, message=FALSE, warning=FALSE}
#Word Cloud 

library(wordcloud)

m <- as.matrix(myTdm)

wordFreq <- sort(rowSums(m),decreasing=TRUE)

set.seed(375)

pal <- brewer.pal(8,"Dark2")

wordcloud(words=names(wordFreq),freq=wordFreq,min.freq=10,random.order=F, rot.per=.1,colors=pal)

```

---

단어 기반 계층적 클러스터링 

1. 어느정도 다양한 트윗에서 존재하는 존재하는 단어들만 추린다. 
1. 스케일링 
1. 거리 행렬 계산 
1. 덴드로그램(dendrogram) 플로팅, 10개의 클러스터 만을 추린다.   


```{r fig.width=7, fig.height=6, message=FALSE, warning=FALSE}
myTdm2<-removeSparseTerms(myTdm,sparse=0.95)
m2<-as.matrix(myTdm2)

distMatrix<-dist(scale(m2))

fit<-hclust(distMatrix,method="ward")

plot(fit)

rect.hclust(fit,k=10)

#(groups<-cutree(fit,k=10))

```


---

k-means 클러스터링 


```{r kmeans,message=FALSE}
m3 <- t(m2)
k <- 4
kmres <- kmeans(m3, k)

round(kmres$centers, digits=3)


for(i in 1:k){
  cat(paste("cluster ", i, " : ", sep=""))
  s <- sort(kmres$centers[i, ], decreasing=T)
  cat(names(s)[1:3], "\n")
  #print(head(rdmTweets[which(kmres$cluster ==i)],n=3))
}
```

---


Silhouette Plot을 보여준다.


```{r kmedoid, message=FALSE}
library(fpc)
pamResult <- pamk(m3, metric="manhattan")
(k <- pamResult$nc)

pamResult <- pamResult$pamobject
#print cluster medoids

for(i in 1:k){
  cat(paste("cluster",i,":"))
  cat(colnames(pamResult$medoids)[which(pamResult$medoids[i,]==1)],"\n")
  # print tweets in cluster i
  #print(rdmTweets[pamResult$clustering==i])
}
```

---

```{r fig.width=7, fig.height=6, message=FALSE, warning=FALSE}
#plotclusteringresult
layout(matrix(c(1,2),2,1))#settotwographsperpage
plot(pamResult,color=F,labels=4,lines=0,cex=.8,col.clus=1,col.p=pamResult$clustering)
layout(matrix(1))
```


---


## Reference 

* [R Data Mining](http://www.rdatamining.com/)


[konlp]: http://cran.r-project.org/web/packages/KoNLP/index.html
[tm]: http://cran.r-project.org/web/packages/tm/index.html
